\documentclass[conference]{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{silence}\WarningsOff[latexfont]

\usepackage{amsmath}

\RequirePackage{tikz}[2010/10/13]
\usetikzlibrary{arrows,automata,calc,intersections,patterns,decorations.pathmorphing,decorations.pathreplacing}

\usepackage{graphicx}
\usepackage{cite}
\usepackage{url}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage[binary-units,per-mode=symbol]{siunitx}
\sisetup{list-final-separator = {, and }}
\usepackage{booktabs}
\usepackage{pifont}
\usepackage{csvsimple}
\usepackage{microtype}
\usepackage{textcomp}
\usepackage[american]{babel}
\usepackage[noabbrev,capitalise]{cleveref}
\usepackage{xspace}
\usepackage{hyphenat}
\usepackage[draft,inline,nomargin,index]{fixme}
\fxsetup{theme=color}
\usepackage{grffile}
\usepackage{xfrac}
\usepackage{multirow}
\RequirePackage{xstring}
\RequirePackage{xparse}
\RequirePackage[index=true]{acro}
\NewDocumentCommand\acrodef{mO{#1}mG{}}{\DeclareAcronym{#1}{short={#2}, long={#3}, #4}}
\NewDocumentCommand\acused{m}{\acuse{#1}}
\usepackage{upquote}
\usepackage{siunitx}
\newcommand*{\mynum}[1]{\num[output-decimal-marker={,},
                             round-mode=places,
                             round-precision=2,
                             group-digits=false]{#1}}
                             

\acrodef{WSN}{Wireless Sensor Network}
\acrodef{MANET}{Mobile Ad Hoc Network}
\acrodef{ROI}{Region of Interest}{short-indefinite={an}, long-plural-form={Regions of Interest}}

\begin{document}

\title{Expanding Vitis Vinifera flavonoid network using Feature Selection Methods}

\author{
	\IEEEauthorblockN{Aliaksandr Siarohin, Mat. number 180402}
	\texttt{aliaksandr.siarohin@studenti.unitn.it}
}

\maketitle

\acresetall

\section{Introduction}
In this project we had been given expression data of vitus vinifera genes, and part of flavonoid pathway. We had been asked to expand this pathway. One way of doing it is to apply feature selection methods. In this project I tried 3 methods: lasso \cite{lasso}, randomized lasso \cite{randomized_lasso} and recursive feature elimination \cite{rfe} with random forest \cite{random_forest}.

\section{Preprocesing}
Expression data contains a lot of NaN values, and in order to apply feature selection methods we first need to deal with this NaNs. I decided to remove all the experiments with amount of NaNs > 5000. And then replace NaNs that left with mean, computed across all genes in given experiment (e.g column mean). The number of removed/replaced can be found in \cref{table:preprocesing}.

\section{Method Description}
Let $G$ - be set of genes, $E$ - set of experiments, $M$ - gene expression matrix. For now let`s assume that we want to predict genes expression of gene $g$, based on all the other genes. We can construct following regression problem $X = M_{E, G/{\{g\}}}^T$, $Y = M_{E, g}^T$, so the regression problem is to predict Y given X. Then using feature selection methods we want to obtain genes that explain (predict) $g$, and ranking of this genes.
\subsection{Lasso}
Lasso method as described in \cite{lasso} has regularization parameter $\alpha$ which controls amount of regularization. I start from 0.1 and try to decrease this parameter until method select 100 genes (The lower $\alpha$ increase computational time, so 100 genes is a trade-of between efficiency and accuracy).
The ranking of genes can be obtaining using absolute value of weight assigned to every selected gene.
\subsection{Randomized lasso}
Randomized lasso as described in \cite{randomized_lasso} run lasso on random subsets of training set (I use 30 runs, and 75 \% of training set for every run). So I use the same setting for estimating alpha (start from 0.1 and decrease until method select 100 genes). The ranking can be obtained from the number of times that method select particular gene.
\subsection{Recursive feature elimination with Random forest}
Recursive feature elimination as described in \cite{rfe} fit regression method on all dataset, than discard feature with the most lowest rating, fit regression on reduced dataset, discard feature with lowest rating and so on, until one feature is left. Random forest on the other hand can produce features ranking, based on the number of times the feature selected when random forest was built. The problem of this method is that for all the genes it take long time to run. So I decided to take genes selected by Lasso method. So this method just assign new ranks. I use random forest with 100 trees in it. And assigned rank using formula:
\begin{equation*}
\frac{1}{n\_features - step\_at\_which\_feature\_was\_discarded}
\end{equation*}
I ran this 3 methods for every target gene in the flavonoid pathway.


\subsection{Method Comparison}
To compare methods I select 100 top rated genes and use 2 metrics average: number of genes from pathway selected by method and average \texttt{DCG}\footnote{\url{https://en.wikipedia.org/wiki/Discounted_cumulative_gain}}(gene from pathway get relevance equal to 1, and not from pathway get relevance equal to zero). The result is in \cref{table:method_comparison}. From this table we can see that all methods show more or less the same performance.


\section{Final Result}
To obtaining final result I use rank aggregation described in \cite{rang_aggr}. I aggregate list for all methods and for all genes, and select best 25. Highest rated get highest rank. The results can be found in \cref{table:selectedTop10} and in \cref{table:selectedNotPathway}.

\begin{table}
\centering
\caption{Preprocesing statistic. Show how many genes and experiments I remove after preprocessing, and how many NaN values we replace with column mean.}
\label{table:preprocesing}
\csvreader[tabular=ccc,
    table head=\toprule Removed Experiments & Removed Genes & Replaced With Mean NaN\\\midrule,
    table foot=\bottomrule
]%
{preprocesing_nan.csv}{NumberOfCellsReplcedWithMean=\mr,NumberOfRemovedExperiments=\re,NumberOfRemovedGenes=\rg}%
{\re & \rg & \mr}%
\end{table}

\begin{table}
\centering
\caption{Features selection method comparison.}
\label{table:method_comparison}
\csvreader[tabular=ccc,
    table head=\toprule Method & Average number of pathway genes & Average DCG\\\midrule,
    table foot=\bottomrule
]%
{method_comparison.csv}{Method=\m,DCG=\d,NumberOfPatwayGenes=\n}%
{\m & \mynum{\n} & \mynum{\d}}%
\end{table}

\begin{table}
\centering
\caption{Top10 final genes selected by aggregating results of all methods.}
\label{table:selectedTop10}
\csvreader[tabular=ccc,
    table head=\toprule Rank & Gene & Is in pathway \\\midrule,
    table foot=\bottomrule
]%
{selected_genes_list_10.csv}{Rank=\r,Genes=\g,InPathway=\i}%
{\r & \g & \i}%
\end{table}

\begin{table}
\centering
\caption{Top10 from final genes, that are not in pathway, selected by aggregating results of all methods.}
\label{table:selectedNotPathway}
\csvreader[tabular=cc,
    table head=\toprule Rank & Gene \\\midrule,
    table foot=\bottomrule
]%
{selected_genes_not_pathway.csv}{Rank=\r,Genes=\g}%
{\r & \g}%
\end{table}





\bibliographystyle{IEEEtran}
\bibliography{references}


\end{document}
